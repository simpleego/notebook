# 딥러닝 교과서
## 1 딥러닝 개요

### 1.1 딥러닝이란?
### 1.2 인공 신경망의 탄생
### 1.3 딥러닝의 역사

## 2 순방향 신경망

### 2.1 순방향 신경망의 구조와 설계 항목
### 2.2 분류와 회귀 문제
### 2.3 이진 분류 모델
### 2.4 다중 분류 모델
### 2.5 회귀 모델
### 2.6 입력 계층
### 2.7 활성 함수
### 2.8 신경망 모델의 크기
### 2.9 신경망 학습 관련 내용(*)

## 3 신경망 학습

### 3.1 신경망 학습의 의미
### 3.2 신경망 학습과 최적화
### 3.3 경사 하강법
### 3.4 역전파 알고리즘
### 3.5 데이터셋 구성과 훈련 데이터 단위
### 3.6 손실 함수 정의(*)

## 4 최적화

### 4.1 확률적 경사 하강법
### 4.2 SGD 모멘텀
### 4.3 네스테로프 모멘텀
### 4.4 AdaGrad
### 4.5 RMSProp
### 4.6 Adam

## 5 초기화와 정규화

### 5.1 가중치 초기화
### 5.2 정규화
### 5.3 배치 정규화
### 5.4 가중치 감소

## 6 콘벌루션 신경망

### 6.1 시각 패턴 인식을 위한 신경망 모델
### 6.2 콘벌루션 신경망의 구조
### 6.3 콘벌루션 신경망의 가정 사항
### 6.4 개선된 콘벌루션 연산
### 6.5 업샘플링 연산

## 7 콘벌루션 신경망 모델

### 7.1 르넷-5
### 7.2 알렉스넷
### 7.3 제트에프넷
### 7.4 브이지지넷
### 7.5 구글넷
### 7.6 레즈넷
### 7.7 콘벌루션 신경망 비교
### 7.8 다양한 모델의 등장

## 8 순환 신경망

### 8.1 기억을 갖는 신경망 모델 RNN
### 8.2 순환 신경망의 주요 모델
### 8.3 시간펼침 역전파
### 8.4 LSTM과 GRU
### 8.5 순환 신경망 개선

## 9 생성 모델

### 9.1 생성 모델
### 9.2 VAE
### 9.3 GAN
